{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a823e7-eca5-4d34-8dbc-6aa1050d289e",
   "metadata": {},
   "source": [
    "# 评估simple rag中的块大小\n",
    "选择合适的块大小对rag管道检索的准确性至关重要。\n",
    "---\n",
    "以下方式评估不同的块大小:\n",
    "- 从 PDF 中提取文本\n",
    "- 将文本分割成不同大小的块\n",
    "- 为每个块创建嵌入\n",
    "- 为查询检索相关块\n",
    "- 使用检索到的块生成响应\n",
    "- 评估响应质量\n",
    "- 比较不同块大小的结果\n",
    "---\n",
    "实现步骤：\n",
    "- 提取文本：按页面\n",
    "- 分割成大小不同的块，并创建嵌入\n",
    "- 根据查询检索相关块\n",
    "- 使用检索到的文本块用模型生成回答\n",
    "- 评估不同大小快的检索回答质量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee66652-efef-4e5a-ab41-b15d9099ce1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境已配置\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "try:\n",
    "    load_dotenv()\n",
    "    print(\"环境已配置\")\n",
    "except:\n",
    "    print(\"检查环境文件是否已配置\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c97e92-9a01-468f-84cc-dbb1ce76cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(\n",
    "    api_key = os.getenv(\"API_KEY\"),\n",
    "    transport=\"rest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54101f98-5413-4816-8a2b-8bb1e6e70ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "理解⼈⼯智能\n",
      "第⼀章：⼈⼯智能简介\n",
      "⼈⼯智能 (AI) 是指数字计算机或计算机控制的机器⼈执⾏通常与智能⽣物相关的任务的能⼒。该术\n",
      "语通常⽤于开发具有⼈类特有的智⼒过程的系统，例如推理、发现意义、概括或从过往经验中学习\n",
      "的能⼒。在过去的⼏⼗年中，计算能⼒和数据可⽤性的进步显著加速了⼈⼯智能的开发和部署。\n",
      "历史背景\n",
      "⼈⼯智能的概念已存在数个世纪，经常出现在神话和⼩说中。然⽽，⼈⼯智能研究的正式领域始于\n",
      "20世纪中叶。1956年的达特茅斯研讨会被⼴泛认为是⼈⼯智能的发源地。早期的⼈⼯智能研究侧\n",
      "重于问题解决和符号⽅法。20世纪80年代专家系统兴起，⽽20世纪90年代和21世纪初，机器学习\n",
      "和神经⽹络取得了进步。深度学习的最新突破彻底改变了这⼀领域。\n",
      "现代观察\n",
      "现代⼈⼯智能系统在⽇常⽣活中⽇益普及。从 Siri 和 Alexa 等虚拟助⼿，到流媒体服务和社交媒体\n",
      "上的推荐算法，⼈⼯智能正在影响我们的⽣活、⼯作和互动⽅式。⾃动驾驶汽⻋、先进的医疗诊断\n",
      "技术以及复杂的⾦融建模⼯具的发展，彰显了⼈⼯智能应⽤的⼴泛性和持续增⻓。此外，⼈们对其\n",
      "伦理影响、偏⻅和失业的担忧也⽇益凸显。\n",
      "第⼆章：⼈⼯智能\n"
     ]
    }
   ],
   "source": [
    "def extra_text_from_pdf(pdf_path):\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"\n",
    "\n",
    "    for page in mypdf:\n",
    "        all_text += page.get_text(\"text\") + \" \"\n",
    "\n",
    "    return all_text.strip()\n",
    "\n",
    "pdf_path = \"../data/AI_Information.en.zh-CN.pdf\"\n",
    "extra_text = extra_text_from_pdf(pdf_path)\n",
    "print(extra_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4892305-ea32-4a9b-af99-e3310dd70c61",
   "metadata": {},
   "source": [
    "# 对提取的文本块进行分块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33dbe662-2fbf-429a-9ac7-80652af69628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_size:128, Number of chunks:98\n",
      "chunk_size:256, Number of chunks:50\n",
      "chunk_size:512, Number of chunks:25\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    将文本分割为重叠的块\n",
    "    参数：\n",
    "    text（str）：要分割的文本\n",
    "    n(int):每个块的字符数\n",
    "    overlap(int):需要重叠的字符数\n",
    "\n",
    "    return：\n",
    "    List[str]:文本块列表\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), n-overlap):\n",
    "        try:\n",
    "            chunks.append(text[i:i+n])\n",
    "        except:\n",
    "            chunks.append(text[i:])\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# 定义需要评估的不同块\n",
    "chunk_sizes = [128, 256, 512]\n",
    "\n",
    "# 创建字典存储每个块大小对应的文本块\n",
    "text_chunks_dict = {size:chunk_text(extra_text, size, size//5) for size in chunk_sizes}\n",
    "# print(text_chunks_dict)\n",
    "# 打印每个块大小生成的块数量\n",
    "for size, chunks in text_chunks_dict.items():\n",
    "    print(f\"chunk_size:{size}, Number of chunks:{len(chunks)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34788f-f752-4dde-a070-4a9b7c43a0f6",
   "metadata": {},
   "source": [
    "# 为文本片段创建嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17e456f-e423-4ede-9666-3de9947c938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "# 假设client已经被正确初始化和配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5e1380-0eb6-4428-bbad-b8e3ebe9b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings:   0%|                                                                     | 0/3 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m chunk_embeddings_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m size, chunks \u001b[38;5;129;01min\u001b[39;00m tqdm(text_chunks_dict\u001b[38;5;241m.\u001b[39mitems(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating Embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 30\u001b[0m     chunk_embeddings_dict[size] \u001b[38;5;241m=\u001b[39m create_embeddings(chunks)\n",
      "Cell \u001b[1;32mIn[17], line 23\u001b[0m, in \u001b[0;36mcreate_embeddings\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     17\u001b[0m     response \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39membed_content(\n\u001b[0;32m     18\u001b[0m     model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEMBEDDING_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     19\u001b[0m     content \u001b[38;5;241m=\u001b[39m texts,\n\u001b[0;32m     20\u001b[0m     task_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETRIEVAL_DOCUMENT\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# 将响应转换为numpy数组列表并添加到embeddings列表中\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend([np\u001b[38;5;241m.\u001b[39marray(embedding\u001b[38;5;241m.\u001b[39membedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "def create_embeddings(texts):\n",
    "    \"\"\"\n",
    "    为文本列表生成嵌入\n",
    "\n",
    "    Args:\n",
    "    texts (List[str]): 输入文本列表.\n",
    "\n",
    "    Returns:\n",
    "    List[np.ndarray]: List of numerical embeddings.\n",
    "    \"\"\"\n",
    "    # 确保每次调用不超过64条文本\n",
    "    batch_size = 64\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        response = genai.embed_content(\n",
    "        model = os.getenv(\"EMBEDDING_MODEL\"),\n",
    "        content = texts,\n",
    "        task_type = \"RETRIEVAL_DOCUMENT\"\n",
    "    )\n",
    "        # 将响应转换为numpy数组列表并添加到embeddings列表中\n",
    "        embeddings.extend([np.array(embedding.embedding) for embedding in response.data])\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# 假设text_chunks_dict是一个字典，键是块大小，值是文本块列表\n",
    "chunk_embeddings_dict = {}\n",
    "for size, chunks in tqdm(text_chunks_dict.items(), desc=\"Generating Embeddings\"):\n",
    "    chunk_embeddings_dict[size] = create_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b2221c-4175-4ecd-ac4a-90d8f744d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "    vec1 (np.ndarray): First vector.\n",
    "    vec2 (np.ndarray): Second vector.\n",
    "\n",
    "    Returns:\n",
    "    float: Cosine similarity score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the dot product of the two vectors\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec97048-bcee-4395-b82f-800a701b75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, text_chunks, chunk_embeddings, k=5):\n",
    "    \"\"\"\n",
    "    检索与查询最相关的前k个文本块\n",
    "\n",
    "    Args:\n",
    "    query (str): 用户查询\n",
    "    text_chunks (List[str]): 文本块列表\n",
    "    chunk_embeddings (List[np.ndarray]): 文本块的嵌入列表\n",
    "    k (int): 返回的前k个块数量\n",
    "\n",
    "    Returns:\n",
    "    List[str]: 最相关的文本块列表\n",
    "    \"\"\"\n",
    "    # 为查询生成一个嵌入 - 将查询作为列表传递并获取第一个项目\n",
    "    query_embedding = create_embeddings([query])[0]\n",
    "\n",
    "    # 计算查询嵌入与每个块嵌入之间的余弦相似度\n",
    "    similarities = [cosine_similarity(query_embedding, emb) for emb in chunk_embeddings]\n",
    "\n",
    "    # 获取前k个最相似块的索引\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "\n",
    "    # 返回前k个最相关的文本块\n",
    "    return [text_chunks[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec09fea5-d654-448a-8cb6-c6ef95df7f16",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 对于每个块大小，检索相关的文本块\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m retrieved_chunks_dict \u001b[38;5;241m=\u001b[39m {size: retrieve_relevant_chunks(query, text_chunks_dict[size], chunk_embeddings_dict[size]) \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m chunk_sizes}\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 打印块大小为 256 的检索到的文本块\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(retrieved_chunks_dict[\u001b[38;5;241m256\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 128"
     ]
    }
   ],
   "source": [
    "# 从 JSON 文件加载验证数据\n",
    "with open('../data/val.json', encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 从验证数据中提取第一个查询\n",
    "query = data[3]['question']\n",
    "\n",
    "# 对于每个块大小，检索相关的文本块\n",
    "retrieved_chunks_dict = {size: retrieve_relevant_chunks(query, text_chunks_dict[size], chunk_embeddings_dict[size]) for size in chunk_sizes}\n",
    "\n",
    "# 打印块大小为 256 的检索到的文本块\n",
    "print(retrieved_chunks_dict[256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48638cda-873b-446c-bfbc-406a569efb36",
   "metadata": {},
   "source": [
    "# 基于检索到的片段生成响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d165aba3-6d7e-4030-85cd-5ca50381a9ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieved_chunks_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 为每个块大小生成 AI 回答\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m ai_responses_dict \u001b[38;5;241m=\u001b[39m {size: generate_response(query, system_prompt, retrieved_chunks_dict[size]) \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m chunk_sizes}\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 打印块大小为 256 的回答\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(ai_responses_dict[\u001b[38;5;241m256\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retrieved_chunks_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# AI 助手的系统提示\n",
    "system_prompt = \"你是一个AI助手，严格根据给定的上下文进行回答。如果无法直接从提供的上下文中得出答案，请回复：'我没有足够的信息来回答这个问题。'\"\n",
    "\n",
    "def generate_response(query, system_prompt, retrieved_chunks):\n",
    "    \"\"\"\n",
    "    基于检索到的文本块生成 AI 回答。\n",
    "\n",
    "    Args:\n",
    "    query (str): 用户查询\n",
    "    retrieved_chunks (List[str]): 检索到的文本块列表\n",
    "    model (str): AI model.\n",
    "\n",
    "    Returns:\n",
    "    str: AI-generated response.\n",
    "    \"\"\"\n",
    "    # 将检索到的文本块合并为一个上下文字符串\n",
    "    context = \"\\n\".join([f\"Context {i+1}:\\n{chunk}\" for i, chunk in enumerate(retrieved_chunks)])\n",
    "\n",
    "    # 通过组合上下文和查询创建用户提示\n",
    "    user_prompt = f\"{context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "    # Generate the AI response using the specified model\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"LLM_MODEL_ID\"),\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Return the content of the AI response\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 为每个块大小生成 AI 回答\n",
    "ai_responses_dict = {size: generate_response(query, system_prompt, retrieved_chunks_dict[size]) for size in chunk_sizes}\n",
    "\n",
    "# 打印块大小为 256 的回答\n",
    "print(ai_responses_dict[256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c911d1f-386f-4a24-aced-7f4edee16103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估评分系统的常量\n",
    "SCORE_FULL = 1.0     # 完全匹配或完全令人满意\n",
    "SCORE_PARTIAL = 0.5  # 部分匹配或部分令人满意\n",
    "SCORE_NONE = 0.0     # 无匹配或不令人满意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc05f92d-a38d-4e1d-94ad-41d043a794ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义严格的评估提示模板\n",
    "FAITHFULNESS_PROMPT_TEMPLATE = \"\"\"\n",
    "评估 AI 回答与真实答案的一致性、忠实度。\n",
    "用户查询: {question}\n",
    "AI 回答: {response}\n",
    "真实答案: {true_answer}\n",
    "\n",
    "一致性衡量 AI 回答与真实答案中的事实对齐的程度，且不包含幻觉信息。\n",
    "忠实度衡量的是AI的回答在没有幻觉的情况下与真实答案中的事实保持一致的程度。\n",
    "\n",
    "指示：\n",
    "- 严格使用以下值进行评分：\n",
    "    * {full} = 完全一致，与真实答案无矛盾\n",
    "    * {partial} = 部分一致，存在轻微矛盾\n",
    "    * {none} = 不一致，存在重大矛盾或幻觉信息\n",
    "- 仅返回数值评分（{full}, {partial}, 或 {none}），无需解释或其他附加文本。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b3a663a-9b93-4f9e-a26d-c8f3df617598",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANCY_PROMPT_TEMPLATE = \"\"\"\n",
    "评估 AI 回答与用户查询的相关性。\n",
    "用户查询: {question}\n",
    "AI 回答: {response}\n",
    "\n",
    "相关性衡量回答在多大程度上解决了用户的问题。\n",
    "\n",
    "指示：\n",
    "- 严格使用以下值进行评分：\n",
    "    * {full} = 完全相关，直接解决查询\n",
    "    * {partial} = 部分相关，解决了一些方面\n",
    "    * {none} = 不相关，未能解决查询\n",
    "- 仅返回数值评分（{full}, {partial}, 或 {none}），无需解释或其他附加文本。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d3d04d1-da89-4370-bd1f-ec1841907b50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ai_responses_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m true_answer \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mideal_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# 评估块大小为 256 和 128 的回答\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m faithfulness, relevancy \u001b[38;5;241m=\u001b[39m evaluate_response(query, ai_responses_dict[\u001b[38;5;241m256\u001b[39m], true_answer)\n\u001b[0;32m     72\u001b[0m faithfulness2, relevancy2 \u001b[38;5;241m=\u001b[39m evaluate_response(query, ai_responses_dict[\u001b[38;5;241m128\u001b[39m], true_answer)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# 打印评估分数\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ai_responses_dict' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_response(question, response, true_answer):\n",
    "        \"\"\"\n",
    "        根据忠实度和相关性评估 AI 生成的回答质量\n",
    "\n",
    "        Args:\n",
    "        question (str): 用户的原始问题\n",
    "        response (str): 被评估的 AI 生成的回答\n",
    "        true_answer (str): 作为基准的真实答案\n",
    "\n",
    "        Returns:\n",
    "        Tuple[float, float]: 包含 (忠实度评分, 相关性评分) 的元组。\n",
    "                             每个评分可能是：1.0（完全匹配）、0.5（部分匹配）或 0.0（无匹配）。\n",
    "        \"\"\"\n",
    "        # 格式化评估提示\n",
    "        faithfulness_prompt = FAITHFULNESS_PROMPT_TEMPLATE.format(\n",
    "                question=question,\n",
    "                response=response,\n",
    "                true_answer=true_answer,\n",
    "                full=SCORE_FULL,\n",
    "                partial=SCORE_PARTIAL,\n",
    "                none=SCORE_NONE\n",
    "        )\n",
    "\n",
    "        relevancy_prompt = RELEVANCY_PROMPT_TEMPLATE.format(\n",
    "                question=question,\n",
    "                response=response,\n",
    "                full=SCORE_FULL,\n",
    "                partial=SCORE_PARTIAL,\n",
    "                none=SCORE_NONE\n",
    "        )\n",
    "\n",
    "        # 模型进行忠实度评估\n",
    "        faithfulness_response = client.chat.completions.create(\n",
    "               model=os.getenv(\"LLM_MODEL_ID\"),\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"你是一个客观的评估者，仅返回数值评分。\"},\n",
    "                        {\"role\": \"user\", \"content\": faithfulness_prompt}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "        # 模型进行相关性评估\n",
    "        relevancy_response = client.chat.completions.create(\n",
    "                model=os.getenv(\"LLM_MODEL_ID\"),\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"你是一个客观的评估者，仅返回数值评分。\"},\n",
    "                        {\"role\": \"user\", \"content\": relevancy_prompt}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "        # 提取评分并处理潜在的解析错误\n",
    "        try:\n",
    "                faithfulness_score = float(faithfulness_response.choices[0].message.content.strip())\n",
    "        except ValueError:\n",
    "                print(\"Warning: 无法解析忠实度评分，将默认为 0\")\n",
    "                faithfulness_score = 0.0\n",
    "\n",
    "        try:\n",
    "                relevancy_score = float(relevancy_response.choices[0].message.content.strip())\n",
    "        except ValueError:\n",
    "                print(\"Warning: 无法解析相关性评分，将默认为 0\")\n",
    "                relevancy_score = 0.0\n",
    "\n",
    "        return faithfulness_score, relevancy_score\n",
    "\n",
    "# 第一条验证数据的真实答案\n",
    "true_answer = data[3]['ideal_answer']\n",
    "\n",
    "# 评估块大小为 256 和 128 的回答\n",
    "faithfulness, relevancy = evaluate_response(query, ai_responses_dict[256], true_answer)\n",
    "faithfulness2, relevancy2 = evaluate_response(query, ai_responses_dict[128], true_answer)\n",
    "\n",
    "# 打印评估分数\n",
    "print(f\"忠实度评分 (Chunk Size 256): {faithfulness}\")\n",
    "print(f\"相关性评分 (Chunk Size 256): {relevancy}\")\n",
    "\n",
    "print(f\"\\n\")\n",
    "\n",
    "print(f\"忠实度评分 (Chunk Size 128): {faithfulness2}\")\n",
    "print(f\"忠实度评分 (Chunk Size 128): {relevancy2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80970ed7-75c7-4846-8834-7e845bfe2f50",
   "metadata": {},
   "source": [
    "# 小结\n",
    "本次的分块其实类似于穷举，将几个分块的数量进行对比得到最佳答案。\n",
    "- 重点：最后的评估提示词规范结构化提问和回答需要学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fabb9b-886a-47d0-954c-59ff4d0c310c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
